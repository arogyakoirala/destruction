{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d29a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import gc\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"/scripts\")\n",
    "    \n",
    "from destruction_utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6393a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "CITY = 'aleppo'\n",
    "DATA_DIR = \"../../data\"\n",
    "PRE_IMAGE_INDEX=[0]\n",
    "WINDOW = True\n",
    "WINDOW_SIZE = (20,20)\n",
    "DATASET = 'all'\n",
    "BALANCE=False\n",
    "TILE_SIZE = (128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7b502c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if WINDOW:\n",
    "    window = center_window(f'{DATA_DIR}/{CITY}/others/{CITY}_samples.tif', (WINDOW_SIZE[0]*1, WINDOW_SIZE[1]*1))\n",
    "    samples = read_raster(f'{DATA_DIR}/{CITY}/others/{CITY}_samples.tif', window=window)\n",
    "else:\n",
    "    samples = read_raster(f'{DATA_DIR}/{CITY}/others/{CITY}_samples.tif')\n",
    "images  = search_data(pattern(city=CITY, type='image'), directory=DATA_DIR)\n",
    "labels  = search_data(pattern(city=CITY, type='label'), directory=DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "909a10df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "if DEBUG:\n",
    "    print(samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4518ae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET=='train' or DATASET=='all':\n",
    "    delete_zarr_if_exists(CITY, 'labels_siamese_train', path=DATA_DIR)\n",
    "    delete_zarr_if_exists(CITY, 'images_siamese_train_tt', path=DATA_DIR)\n",
    "    delete_zarr_if_exists(CITY, 'images_siamese_train_t0', path=DATA_DIR)\n",
    "\n",
    "if DATASET=='validate' or DATASET=='all':\n",
    "    delete_zarr_if_exists(CITY, 'labels_siamese_valid', path=DATA_DIR)\n",
    "    delete_zarr_if_exists(CITY, 'images_siamese_valid_tt', path=DATA_DIR)\n",
    "    delete_zarr_if_exists(CITY, 'images_siamese_valid_t0', path=DATA_DIR)\n",
    "\n",
    "if DATASET=='test' or DATASET=='all':\n",
    "    delete_zarr_if_exists(CITY, 'labels_siamese_test', path=DATA_DIR)\n",
    "    delete_zarr_if_exists(CITY, 'images_siamese_test_tt', path=DATA_DIR)\n",
    "    delete_zarr_if_exists(CITY, 'images_siamese_test_t0', path=DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b1c220d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-05-23 2013_09_23\n",
      "2015-04-26 2014_07_14\n",
      "2015-05-01 2014_07_14\n"
     ]
    }
   ],
   "source": [
    "image_dates = sorted([el.split(\"image_\")[1].split('.tif')[0] for el in images])\n",
    "label_dates = sorted([el.split(\"label_\")[1].split('.tif')[0] for el in labels])\n",
    "\n",
    "for label in label_dates:\n",
    "    if label.replace(\"-\", \"_\") not in image_dates:\n",
    "        latest_available_image = sorted([im for im in image_dates if time.strptime(im, \"%Y_%m_%d\")  < time.strptime(label, \"%Y-%m-%d\")])\n",
    "        latest_available_image = latest_available_image[-1]\n",
    "        if DEBUG:\n",
    "            print(label, latest_available_image)\n",
    "        images.append(images[0].split(\"image_\")[0]+\"image_\"+latest_available_image+\".tif\")\n",
    "images = sorted(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "935f152a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/aleppo/images/image_2011_01_01.tif\n",
      "../../data/aleppo/images/image_2013_05_26.tif\n",
      "../../data/aleppo/images/image_2013_09_23.tif\n",
      "../../data/aleppo/images/image_2013_09_23.tif\n",
      "../../data/aleppo/images/image_2014_07_14.tif\n",
      "../../data/aleppo/images/image_2014_07_14.tif\n",
      "../../data/aleppo/images/image_2014_07_14.tif\n",
      "../../data/aleppo/images/image_2016_03_29.tif\n",
      "../../data/aleppo/images/image_2016_09_18.tif\n"
     ]
    }
   ],
   "source": [
    "if DEBUG:\n",
    "    for image in images:\n",
    "        print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0c80aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Using pre image #1..\n",
      "--------- Image 1 of 8 done..\n",
      "--------- Image 2 of 8 done..\n",
      "--------- Image 3 of 8 done..\n",
      "--------- Image 4 of 8 done..\n",
      "--------- Image 5 of 8 done..\n",
      "--------- Image 6 of 8 done..\n",
      "--------- Image 7 of 8 done..\n",
      "--------- Image 8 of 8 done..\n"
     ]
    }
   ],
   "source": [
    "for j, pre_image_index in enumerate(PRE_IMAGE_INDEX):\n",
    "    print(f'------ Using pre image #{j+1}..')\n",
    "\n",
    "    if WINDOW:\n",
    "        window = center_window(images[pre_image_index], (WINDOW_SIZE[0]*TILE_SIZE[0], WINDOW_SIZE[1]*TILE_SIZE[1]))\n",
    "        pre_image = read_raster(images[pre_image_index], window=window)\n",
    "    else:\n",
    "        pre_image = read_raster(images[pre_image_index])\n",
    "    \n",
    "    pre_image = tile_sequences(np.array([pre_image]), TILE_SIZE)\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        if i not in PRE_IMAGE_INDEX:\n",
    "            if WINDOW:\n",
    "                window = center_window(labels[i], (WINDOW_SIZE[0]*1, WINDOW_SIZE[1]*1))\n",
    "                label = np.array(read_raster(labels[i], window=window))\n",
    "            else:\n",
    "                label = np.array(read_raster(labels[i]))\n",
    "            label = label.flatten()\n",
    "            exclude = np.where(label==-1.0)\n",
    "            label = np.delete(label, exclude)\n",
    "            samples_valid = np.delete(samples.flatten(), exclude)\n",
    "            _, label_train, label_test, label_valid = sample_split(label, samples_valid )\n",
    "\n",
    "            if DATASET=='train' or DATASET=='all':\n",
    "                save_zarr(np.equal(label_train, 3), CITY, 'labels_siamese_train', path=DATA_DIR)\n",
    "            if DATASET=='validate' or DATASET=='all':\n",
    "                save_zarr(np.equal(label_valid, 3), CITY, 'labels_siamese_valid', path=DATA_DIR)\n",
    "            if DATASET=='test' or DATASET=='all':\n",
    "                save_zarr(np.equal(label_test, 3), CITY, 'labels_siamese_test', path=DATA_DIR)\n",
    "\n",
    "\n",
    "            \n",
    "            if WINDOW:\n",
    "                window = center_window(images[i], (WINDOW_SIZE[0]*TILE_SIZE[0], WINDOW_SIZE[1]*TILE_SIZE[1]))\n",
    "                image = np.array(read_raster(images[i], window=window))\n",
    "            else:\n",
    "                image = np.array(read_raster(images[i]))\n",
    "            image = tile_sequences(np.array([image]), TILE_SIZE)\n",
    "            image = np.delete(image, exclude, 0)\n",
    "            _, image_train, image_test, image_valid = sample_split(image, samples_valid)\n",
    "            if DATASET=='train' or DATASET=='all':\n",
    "                save_zarr(flatten_image(image_train), CITY, 'images_siamese_train_tt', path=DATA_DIR)\n",
    "            if DATASET=='validate' or DATASET=='all':\n",
    "                save_zarr(flatten_image(image_valid), CITY, 'images_siamese_valid_tt', path=DATA_DIR)\n",
    "            if DATASET=='test' or DATASET=='all':\n",
    "                save_zarr(flatten_image(image_test), CITY, 'images_siamese_test_tt', path=DATA_DIR)\n",
    " \n",
    "            pre_image_v = np.delete(pre_image, exclude, 0)\n",
    "            _, pre_image_train, pre_image_test, pre_image_valid = sample_split(pre_image_v, samples_valid)\n",
    "            if DATASET=='train' or DATASET=='all':\n",
    "                save_zarr(flatten_image(pre_image_train), CITY, 'images_siamese_train_t0', path=DATA_DIR)\n",
    "            if DATASET=='validate' or DATASET=='all':\n",
    "                save_zarr(flatten_image(pre_image_valid), CITY, 'images_siamese_valid_t0', path=DATA_DIR)\n",
    "            if DATASET=='test' or DATASET=='all':\n",
    "                save_zarr(flatten_image(pre_image_test), CITY, 'images_siamese_test_t0', path=DATA_DIR)\n",
    "            print(f'--------- Image {i+1 - len(PRE_IMAGE_INDEX)} of {len(images) - len(PRE_IMAGE_INDEX)} done..')\n",
    "\n",
    "if DATASET=='train' or DATASET=='all':\n",
    "    # Generate a balanced (upsampled) dataset and shuffle it..\n",
    "    delete_zarr_if_exists(CITY, 'labels_siamese_train_balanced')\n",
    "    delete_zarr_if_exists(CITY, 'images_siamese_train_t0_balanced')\n",
    "    delete_zarr_if_exists(CITY, 'images_siamese_train_tt_balanced')\n",
    "    if BALANCE:\n",
    "        print('--- Generate a balanced (upsampled) dataset..')\n",
    "        balance_snn(CITY)\n",
    "    print('--- Shuffle dataset..')\n",
    "    shuffle_snn(CITY, TILE_SIZE, (100,750))\n",
    "\n",
    "\n",
    "print('--- Process complete.. \\n')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ed3f391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading image: ../../data/aleppo/others/aleppo_images_siamese_valid_tt.zarr\n"
     ]
    }
   ],
   "source": [
    "t = read_zarr(CITY, \"images_siamese_valid_tt\", path=DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cba7e5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 49.,  36.,  25.],\n",
       "        [ 49.,  32.,  16.],\n",
       "        [132., 117., 107.],\n",
       "        ...,\n",
       "        [132., 113., 107.],\n",
       "        [132., 113., 107.],\n",
       "        [140., 121., 115.]],\n",
       "\n",
       "       [[ 33.,  16.,   8.],\n",
       "        [ 58.,  40.,  33.],\n",
       "        [132., 117., 107.],\n",
       "        ...,\n",
       "        [ 74.,  57.,  49.],\n",
       "        [ 99.,  81.,  74.],\n",
       "        [156., 142., 132.]],\n",
       "\n",
       "       [[ 41.,  32.,  25.],\n",
       "        [ 74.,  61.,  49.],\n",
       "        [132., 113., 107.],\n",
       "        ...,\n",
       "        [ 66.,  53.,  41.],\n",
       "        [ 82.,  73.,  66.],\n",
       "        [115.,  97.,  90.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[165., 154., 140.],\n",
       "        [181., 170., 156.],\n",
       "        [173., 166., 156.],\n",
       "        ...,\n",
       "        [173., 162., 140.],\n",
       "        [148., 142., 123.],\n",
       "        [148., 138., 123.]],\n",
       "\n",
       "       [[123., 113.,  99.],\n",
       "        [ 99.,  93.,  74.],\n",
       "        [ 90.,  85.,  66.],\n",
       "        ...,\n",
       "        [173., 166., 148.],\n",
       "        [165., 158., 140.],\n",
       "        [165., 154., 140.]],\n",
       "\n",
       "       [[123., 109.,  99.],\n",
       "        [ 58.,  53.,  41.],\n",
       "        [ 25.,  20.,   8.],\n",
       "        ...,\n",
       "        [165., 150., 140.],\n",
       "        [165., 154., 140.],\n",
       "        [173., 162., 148.]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3376217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
